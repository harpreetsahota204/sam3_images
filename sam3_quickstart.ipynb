{
  "cells": [
    {
      "cell_type": "markdown",
      "metadata": {},
      "source": [
        "# SAM3 for FiftyOne - Quick Start\n",
        "\n",
        "[![Open In Colab](https://colab.research.google.com/assets/colab-badge.svg)](https://colab.research.google.com/github/harpreetsahota204/sam3_images/blob/main/sam3_quickstart.ipynb)\n",
        "\n",
        "Complete guide to using Meta's SAM3 (Segment Anything Model 3) in FiftyOne.\n",
        "\n",
        "**Features:**\n",
        "- ðŸŽ¯ Concept Segmentation (text prompts)\n",
        "- ðŸ–±ï¸ Visual Segmentation (interactive prompts)\n",
        "- ðŸ¤– Automatic Segmentation (no prompts)\n",
        "- ðŸ” Visual Embeddings (1024-dim)\n"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {},
      "source": [
        "## 1. Installation\n",
        "\n",
        "SAM3 requires transformers from source (not yet on PyPI):\n"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {},
      "outputs": [],
      "source": [
        "%pip install -q git+https://github.com/huggingface/transformers.git#egg=transformers\n",
        "%pip install -q fiftyone torch torchvision huggingface-hub umap-learn\n"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {},
      "source": [
        "## 2. Setup\n"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {},
      "outputs": [],
      "source": [
        "import fiftyone as fo\n",
        "import fiftyone.zoo as foz\n",
        "import fiftyone.brain as fob\n",
        "\n",
        "# Load dataset\n",
        "dataset = foz.load_zoo_dataset(\"quickstart\", max_samples=200)\n",
        "\n",
        "# Register SAM3 zoo model\n",
        "foz.register_zoo_model_source(\n",
        "    \"https://github.com/harpreetsahota204/sam3_images\"\n",
        ")\n",
        "\n",
        "# Load model\n",
        "model = foz.load_zoo_model(\"facebook/sam3\")\n",
        "\n",
        "print(f\"âœ… Loaded {len(dataset)} samples\")\n"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {},
      "source": [
        "## 3. Visual Embeddings\n",
        "\n",
        "Extract 1024-dim embeddings for similarity search:\n"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {},
      "outputs": [],
      "source": [
        "# Compute embeddings\n",
        "model.pooling_strategy = \"max\"  # or \"mean\", \"cls\"\n",
        "\n",
        "dataset.compute_embeddings(\n",
        "    model,\n",
        "    embeddings_field=\"sam_embeddings\",\n",
        "    batch_size=32\n",
        ")\n",
        "\n",
        "print(\"âœ… Embeddings computed\")\n"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {},
      "outputs": [],
      "source": [
        "# Visualize with UMAP\n",
        "fob.compute_visualization(\n",
        "    dataset,\n",
        "    method=\"umap\",\n",
        "    brain_key=\"sam_viz\",\n",
        "    embeddings=\"sam_embeddings\",\n",
        "    num_dims=2\n",
        ")\n",
        "\n",
        "print(\"âœ… UMAP visualization ready\")\n"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {},
      "source": [
        "## 4. Concept Segmentation\n",
        "\n",
        "Find ALL instances matching text concepts:\n"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {},
      "outputs": [],
      "source": [
        "# Single concept\n",
        "model.operation = \"concept_segmentation\"\n",
        "model.prompt = \"person\"\n",
        "model.threshold = 0.5\n",
        "model.mask_threshold = 0.5\n",
        "\n",
        "dataset.apply_model(\n",
        "    model,\n",
        "    label_field=\"people\",\n",
        "    batch_size=16,\n",
        "    num_workers=4\n",
        ")\n"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {},
      "outputs": [],
      "source": [
        "# Multiple concepts (runs once per concept - slower!)\n",
        "# 7 concepts = 7x inference passes\n",
        "model.prompt = [\n",
        "    \"bird\", \"human\", \"land vehicle\", \"air vehicle\",\n",
        "    \"animal\", \"food\", \"furniture\"\n",
        "]\n",
        "\n",
        "dataset.apply_model(\n",
        "    model,\n",
        "    label_field=\"multi_concept\",\n",
        "    batch_size=8,\n",
        "    num_workers=4\n",
        ")\n"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {},
      "source": [
        "## 5. Visual Segmentation\n",
        "\n",
        "Refine existing detections into precise masks:\n"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {},
      "outputs": [],
      "source": [
        "model.operation = \"visual_segmentation\"\n",
        "\n",
        "dataset.apply_model(\n",
        "    model,\n",
        "    label_field=\"visual_masks\",\n",
        "    prompt_field=\"ground_truth\",  # Use existing detections as prompts\n",
        "    batch_size=64,\n",
        "    num_workers=4\n",
        ")\n"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {},
      "source": [
        "## 6. Automatic Segmentation\n",
        "\n",
        "Segment everything with quality filtering:\n"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {},
      "outputs": [],
      "source": [
        "model.operation = \"automatic_segmentation\"\n",
        "model.auto_kwargs = {\n",
        "    \"points_per_side\": 16,       # Grid: 16x16 = 256 points\n",
        "    \"points_per_batch\": 256,     # Batch size\n",
        "    \"quality_threshold\": 0.8,    # Keep high quality only\n",
        "    \"iou_threshold\": 0.85,       # Remove duplicates\n",
        "    \"max_masks\": 100             # Top 100 masks\n",
        "}\n",
        "\n",
        "# Run on subset (automatic is slow)\n",
        "dataset.take(10).apply_model(\n",
        "    model,\n",
        "    label_field=\"auto_masks\",\n",
        "    batch_size=2,\n",
        "    num_workers=2\n",
        ")\n",
        "\n"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {},
      "source": [
        "## 7. Launch FiftyOne App\n"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {},
      "outputs": [],
      "source": [
        "session = fo.launch_app(dataset)\n",
        "\n",
        "# In Colab, use:\n",
        "# session = fo.launch_app(dataset, auto=True)\n",
        "# print(session.url)\n"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {},
      "source": [
        "## 8. Explore Results\n"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {},
      "outputs": [],
      "source": [
        "from fiftyone import ViewField as F\n",
        "\n",
        "# Filter by label\n",
        "people = dataset.filter_labels(\"people\", F(\"label\") == \"person\")\n",
        "print(f\"Found people in {len(people)} samples\")\n",
        "\n",
        "# Filter by confidence\n",
        "high_conf = dataset.filter_labels(\"multi_concept\", F(\"confidence\") > 0.8)\n",
        "print(f\"High confidence detections: {len(high_conf.exists('multi_concept'))}\")\n",
        "\n",
        "# Similarity search\n",
        "fob.compute_similarity(dataset, embeddings=\"sam_embeddings\")\n",
        "query = dataset.first()\n",
        "similar = dataset.sort_by_similarity(query, k=10)\n",
        "print(f\"Found {len(similar)} similar images\")\n"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {},
      "source": [
        "## Summary\n",
        "\n",
        "You've now:\n",
        "- âœ… Computed visual embeddings for similarity search\n",
        "- âœ… Found objects using text prompts (concept segmentation)\n",
        "- âœ… Refined detections with precise masks (visual segmentation)\n",
        "- âœ… Generated all possible masks (automatic segmentation)\n",
        "\n",
        "**Next Steps:**\n",
        "- Try different prompts for concept segmentation\n",
        "- Adjust thresholds for more/fewer detections\n",
        "- Experiment with automatic segmentation parameters\n",
        "\n",
        "**Documentation:** https://github.com/harpreetsahota204/sam3_images\n"
      ]
    }
  ],
  "metadata": {
    "language_info": {
      "name": "python"
    }
  },
  "nbformat": 4,
  "nbformat_minor": 2
}
